{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6529ece7-9e19-4b22-8416-ff07955b1578",
   "metadata": {},
   "source": [
    "# Abigail's code try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f92916-a9c0-4213-9f57-6924cd4ea13e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting wandb\n",
      "  Obtaining dependency information for wandb from https://files.pythonhosted.org/packages/5c/81/1780aa129564b11709a6d7f0739257174f0a3a1b432ba804b3c6f00e0f88/wandb-0.16.0-py3-none-any.whl.metadata\n",
      "  Using cached wandb-0.16.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (3.1.32)\n",
      "Requirement already satisfied: requests<3,>=2.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (2.31.0)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (5.9.5)\n",
      "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
      "  Obtaining dependency information for sentry-sdk>=1.0.0 from https://files.pythonhosted.org/packages/ee/61/72bf9b0326f77486403f468b0466a3eeb6f7613ba96b714f6974fe6b9c36/sentry_sdk-1.38.0-py2.py3-none-any.whl.metadata\n",
      "  Using cached sentry_sdk-1.38.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
      "  Using cached docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "Requirement already satisfied: PyYAML in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (5.4.1)\n",
      "Collecting setproctitle (from wandb)\n",
      "  Obtaining dependency information for setproctitle from https://files.pythonhosted.org/packages/79/e7/54b36be02aee8ad573be68f6f46fd62838735c2f007b22df50eb5e13a20d/setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
      "  Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: setuptools in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (68.1.2)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from wandb) (4.21.12)\n",
      "Requirement already satisfied: six>=1.4.0 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from requests<3,>=2.0.0->wandb) (2023.7.22)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /srv/conda/envs/notebook/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (3.0.5)\n",
      "Using cached wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
      "Using cached sentry_sdk-1.38.0-py2.py3-none-any.whl (252 kB)\n",
      "Using cached setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
      "Installing collected packages: setproctitle, sentry-sdk, docker-pycreds, wandb\n",
      "Successfully installed docker-pycreds-0.4.0 sentry-sdk-1.38.0 setproctitle-1.3.3 wandb-0.16.0\n"
     ]
    }
   ],
   "source": [
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec13a3b-58e3-48a6-aed0-fe0340eadbc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "import numpy as np\n",
    "import sys\n",
    "import torch\n",
    "import torch.utils.data as Data\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import pearsonr\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2fed75a2-e6b7-4b2f-901d-d9275f9a5f06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamf2288\u001b[0m (\u001b[33mfagerheim\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "183af403-da9c-4c91-ae82-36baa7a4ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = '~/ML_project/models'\n",
    "PATH_NN= BASE+'NN_data_smooth/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc365c31-be5e-41f9-bbe4-b92915bd70f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from funcs import regression_system\n",
    "from funcs import fcnn\n",
    "from funcs import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "842832de-bd65-4b5d-8115-91b6906e7fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define X,Y pairs (state, subgrid fluxes) for local network.local_torch_dataset = Data.TensorDataset(\n",
    "BATCH_SIZE = 64  # Number of sample in each batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c828399-ad89-49f8-abe9-5327c2fd0ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "submeso_dataset=dataset.SubmesoDataset(['grad_B','FCOR', 'Nsquared', 'HML', 'TAU',\n",
    "              'Q', 'HBL', 'div', 'vort', 'strain'],res='1_4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bc3811d-1f5c-494e-8d9b-c6899841c484",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader=DataLoader(\n",
    "    submeso_dataset,\n",
    "    #num_workers=1,\n",
    "    batch_size=64,\n",
    "    sampler=SubsetRandomSampler(submeso_dataset.train_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02177b1f-7bef-47c6-a442-aa3eac8aa6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader=DataLoader(\n",
    "    submeso_dataset,\n",
    "    #num_workers=1,\n",
    "    batch_size=len(submeso_dataset.test_ind),\n",
    "    sampler=submeso_dataset.test_ind)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760f7626-d54d-47bb-99a9-9c8bd4c44543",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available\n"
     ]
    }
   ],
   "source": [
    "# use GPUs if available\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA Available\")\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    print('CUDA Not Available')\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee73f465-8dfe-4772-8068-2e22432b0ba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed=123\n",
    "batch_size=256\n",
    "input_channels=10\n",
    "output_channels=1\n",
    "conv_layers = 3\n",
    "kernel = 5\n",
    "kernel_hidden =3\n",
    "activation=\"ReLU\"\n",
    "arch=\"fcnn\"\n",
    "epochs=100\n",
    "save_path=BASE+\"trained_models/\"\n",
    "save_name=\"fcnn_k5_l3_res_1_4.pt\"\n",
    "lr=0.00024594159283761457\n",
    "wd=0.023133758465751404"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe7b4833-f6e8-49bb-a846-33fb63018a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Wandb config file\n",
    "config={\"seed\":seed,\n",
    "        \"lr\":lr,\n",
    "        \"wd\":wd,\n",
    "        \"batch_size\":batch_size,\n",
    "        \"input_channels\":input_channels,\n",
    "        \"output_channels\":output_channels,\n",
    "        \"activation\":activation,\n",
    "        \"save_name\":save_name,\n",
    "        \"save_path\":save_path,\n",
    "        \"arch\":arch,\n",
    "        \"conv_layers\":conv_layers,\n",
    "        \"kernel\":kernel,\n",
    "        \"kernel_hidden\":kernel_hidden,\n",
    "        \"epochs\":epochs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60bc2fda-85c5-4ffb-81f1-0429ee4d5ca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cat: /sys/module/amdgpu/initstate: No such file or directory\n",
      "ERROR:root:Driver not initialized (amdgpu not found in modules)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jovyan/ML_project/wandb/run-20231129_215944-3d5ex3bv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fagerheim/submeso_ML/runs/3d5ex3bv' target=\"_blank\">divine-bee-8</a></strong> to <a href='https://wandb.ai/fagerheim/submeso_ML' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fagerheim/submeso_ML' target=\"_blank\">https://wandb.ai/fagerheim/submeso_ML</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fagerheim/submeso_ML/runs/3d5ex3bv' target=\"_blank\">https://wandb.ai/fagerheim/submeso_ML/runs/3d5ex3bv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/pytorch_lightning/loggers/wandb.py:397: UserWarning: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"submeso_ML\",config=config)\n",
    "model=fcnn.FCNN(config)\n",
    "config[\"learnable parameters\"]=sum(p.numel() for p in model.parameters())\n",
    "system=regression_system.RegressionSystem(model,wandb.config[\"lr\"],wandb.config[\"wd\"])\n",
    "wandb.watch(model, log_freq=1)\n",
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "67c17274-f860-4cc6-9d0a-b9a366c1bbe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(\n",
    "    default_root_dir=model.config[\"save_path\"],\n",
    "    accelerator=\"auto\",\n",
    "    max_epochs=config[\"epochs\"],\n",
    "    enable_progress_bar=False,\n",
    "    logger=wandb_logger,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6c06e2a5-fdbd-448d-b70c-553f1e4e862f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name      | Type    | Params\n",
      "--------------------------------------\n",
      "0 | network   | FCNN    | 162 K \n",
      "1 | criterion | MSELoss | 0     \n",
      "--------------------------------------\n",
      "162 K     Trainable params\n",
      "0         Non-trainable params\n",
      "162 K     Total params\n",
      "0.649     Total estimated model params size (MB)\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "/srv/conda/envs/notebook/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:438: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n",
      "`Trainer.fit` stopped: `max_epochs=100` reached.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory ~/ML_project/modelstrained_models does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mfit(system, train_loader, test_loader)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#model.save_model()\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_path\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[1;32m      8\u001b[0m project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msubmeso_ML\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/torch/serialization.py:315\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    314\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/srv/conda/envs/notebook/lib/python3.10/site-packages/torch/serialization.py:288\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory ~/ML_project/modelstrained_models does not exist."
     ]
    }
   ],
   "source": [
    "trainer.fit(system, train_loader, test_loader)\n",
    "#model.save_model()\n",
    "torch.save(model, config[\"save_path\"] + config[\"save_name\"])\n",
    "\n",
    "wandb.finish()\n",
    "    \n",
    "\n",
    "project_name=\"submeso_ML\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a098a16-2ecc-43de-a64a-a7b2759bd296",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "W&B sync reduced upload amount by 6.0%             "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>train_loss</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>valid_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>99</td></tr><tr><td>train_loss</td><td>0.0</td></tr><tr><td>trainer/global_step</td><td>12699</td></tr><tr><td>valid_loss</td><td>0.0</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">divine-bee-8</strong> at: <a href='https://wandb.ai/fagerheim/submeso_ML/runs/3d5ex3bv' target=\"_blank\">https://wandb.ai/fagerheim/submeso_ML/runs/3d5ex3bv</a><br/> View job at <a href='https://wandb.ai/fagerheim/submeso_ML/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExOTc1NDk3Nw==/version_details/v1' target=\"_blank\">https://wandb.ai/fagerheim/submeso_ML/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExOTc1NDk3Nw==/version_details/v1</a><br/>Synced 6 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231129_215944-3d5ex3bv/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ffcefd1-91b5-42cf-a007-056574168d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0005b2e0-5d02-4908-a491-bfbc375e1e98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96b4635-af33-44df-b36e-a0af001cd802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb996ab-1292-4059-b62d-55c0f07e90c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1ecf95-0c28-4215-a5b9-96658e6d0bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063e4d5-6276-441c-aeb6-264600a55190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49ce098c-0696-419e-b4f6-5963d222a369",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e7f8b3-b894-4723-9be1-775dca4c5826",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8917d3-9400-499f-88c7-e46b5772d331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
